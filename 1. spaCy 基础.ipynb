{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1632f138",
   "metadata": {},
   "source": [
    "## spacy基础"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "296a2a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy \n",
    "\n",
    "nlp = spacy.blank('zh') #选择nlp的语言 #zh代表中文"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6550296e",
   "metadata": {},
   "source": [
    "- token.text 可以用来输出文本内容"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b711f4df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This\n",
      "is\n",
      "a\n",
      "sentence\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"This is a sentence.\") # nlp的内容转化为token\n",
    "\n",
    "for token in doc:\n",
    "    print(token.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc1cae5c",
   "metadata": {},
   "source": [
    "- doc[i]可以读取指定的token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "83819c5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the first token in documents: This\n"
     ]
    }
   ],
   "source": [
    "# 输出第一个token\n",
    "\n",
    "first_token = doc[0]\n",
    "\n",
    "print(\"the first token in documents:\", first_token.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7601ed75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is a\n"
     ]
    }
   ],
   "source": [
    "# 输出一串token\n",
    "\n",
    "slice_token = doc[1:3]\n",
    "print(slice_token.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93777015",
   "metadata": {},
   "source": [
    "- like_num 可以用来判断是否是数字\n",
    "- token.i 可以指示当前token的index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bbcc9403",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "percent found 60\n",
      "percent found 4\n"
     ]
    }
   ],
   "source": [
    "doc1 = nlp(\n",
    "    \"In 1990, more than 60% of people in East Asia were in extreme poverty. \"\n",
    "    \"Now less than 4% are.\"\n",
    ")\n",
    "\n",
    "for token in doc1:\n",
    "    # check  if the token is a number\n",
    "    if token.like_num:\n",
    "        # get the next token \n",
    "        next_token = doc1[token.i+1]\n",
    "        # check is the next token is %\n",
    "        if next_token.text == '%':\n",
    "            print(\"percent found\", token.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d196916a",
   "metadata": {},
   "source": [
    "## Trained pipelines 基础\n",
    "\n",
    "### 什么是Trained pipelines？\n",
    "能够在上下文中预测语言属性的模型:包括词性标签、句法依赖和命名实体。\n",
    "eg:一个词是动词还是一段文本是否是人名\n",
    "\n",
    "## piprlines 包\n",
    "使用该spacy download命令下载。\n",
    "\n",
    "#### “zh_core_web_sm”包是一个小型中文管道，函数后面都有下划线\n",
    "- .pos_属性，是词性标注的结果   \n",
    "- .dep_属性返回预测的依存关系标注。\n",
    "- .head属性返回句法头词符。你可以认为这是词在句子中所依附的母词符。\n",
    "\n",
    "#### 例子：我吃了个肉夹馍\n",
    "label1： nsubj， 是名词主语， 我就是依附在吃上面的nsubj\n",
    "label2: dobj， 是目的语，肉夹馍是依附在吃上面的dobj\n",
    "\n",
    "- doc.ents中可以读取命名实体识别模型预测出的所有命名实体。\n",
    "- 其中.label_ 属性来打印出实体标注。\n",
    "- spacy.explain 可以解释label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ba3cbe73",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"zh_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8cf23d65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "微软 ORG\n",
      "十亿美金 MONEY\n",
      "英国 GPE\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Companies, agencies, institutions, etc.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = nlp(\"微软准备用十亿美金买下英国的创业公司\")\n",
    "\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.label_)\n",
    "    \n",
    "spacy.explain(\"ORG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a445e4e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "微软准备用十亿美金买下英国的创业公司\n"
     ]
    }
   ],
   "source": [
    "print(doc.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d4de3eda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "微软 PROPN nsubj\n",
      "准备 VERB ROOT\n",
      "用 ADP case\n",
      "十亿 NUM nmod:prep\n",
      "美金 NUM mark:clf\n",
      "买下 VERB ccomp\n",
      "英国 PROPN dobj\n",
      "的 PART mark\n",
      "创业 NOUN compound:nn\n",
      "公司 NOUN dobj\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(token.text, token.pos_, token.dep_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3613d5a1",
   "metadata": {},
   "source": [
    "## matcher\n",
    "写一些规则来寻找文本中的目标词汇和短语。\n",
    "- 与正则表达式相比，matcher是配合Doc和Token这样的方法来使用的， 而不是只作用于字符串上。\n",
    "- 匹配的模板是一些列表，列表的每一个元素是一个字典。 每个字典代表一个词符，键值是词符属性名，映射到对应的目标值上面。\n",
    "\n",
    "- nlp.vocab来初始化matcher\n",
    "- matcher.add方法可以用来添加一个模板。第一个参数是唯一的ID用来识别匹配的是哪一个模板。 第二个参数是一个模板的列表。\n",
    "\n",
    "- 当你对doc调用matcher时会返回一个列表，列表中的每个元素是一个元组(tuple)。\n",
    "- 每个元组由三个值构成：匹配到的ID，匹配到的跨度的起始和终止索引\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dd30ac29",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.matcher import Matcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c4bd2c19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iPhone X\n"
     ]
    }
   ],
   "source": [
    "# 读取一个流程，创建nlp实例\n",
    "nlp = spacy.load(\"zh_core_web_sm\")\n",
    "\n",
    "# 用模型分享出的vocab初始化matcher\n",
    "matcher = Matcher(nlp.vocab)\n",
    "\n",
    "# 给matcher加入模板\n",
    "pattern = [{\"TEXT\": \"iPhone\"}, {\"TEXT\": \"X\"}]\n",
    "matcher.add(\"IPHONE_PATTERN\", [pattern])\n",
    "\n",
    "# 处理文本\n",
    "doc = nlp(\"即将上市的iPhone X发布日期被泄露了\")\n",
    "\n",
    "# 在doc上面调用matcher\n",
    "matches = matcher(doc)\n",
    "\n",
    "# 遍历所有的匹配结果\n",
    "for match_id, start, end in matches:\n",
    "    # 获取匹配的跨度\n",
    "    matched_span = doc[start:end]\n",
    "    print(matched_span.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4575ee41",
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = [\n",
    "    {\"IS_DIGIT\": True},\n",
    "    {\"LOWER\": \"国际\"},\n",
    "    {\"LOWER\": \"足联\"},\n",
    "    {\"LOWER\": \"世界杯\"},\n",
    "    {\"IS_PUNCT\": True}\n",
    "]\n",
    "doc = nlp(\"2018国际足联世界杯：法国队赢了！\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "96b3481d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 一个词根是\"喜欢\"的动词，后面跟着一个名词。\n",
    "pattern1 = [\n",
    "    {\"LEMMA\": \"喜欢\", \"POS\": \"VERB\"},\n",
    "    {\"POS\": \"NOUN\"}\n",
    "]\n",
    "doc = nlp(\"我喜欢狗但我更喜欢猫。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e6546ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用运算符和量词来定义一个词符应该被匹配几次。 我们可以用\"OP\"这个关键词来添加它们。\n",
    "pattern = [\n",
    "    {\"LEMMA\": \"买\"},\n",
    "    {\"POS\": \"NUM\", \"OP\": \"?\"},  # 可选: 匹配0次或者1次\n",
    "    {\"POS\": \"NOUN\"}\n",
    "]\n",
    "doc = nlp(\"我买个肉夹馍。我还要买凉皮。\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee9491d2",
   "metadata": {},
   "source": [
    "- {\"OP\": \"!\"}\t否定: 0次匹配\n",
    "- {\"OP\": \"?\"}\t可选: 0次或1次匹配\n",
    "- {\"OP\": \"+\"}\t1次或更多次匹配\n",
    "- {\"OP\": \"*\"}\t0次或更多次匹配"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "43cf3748",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total matches found: 3\n",
      "Match found: iOS 7\n",
      "Match found: iOS 11\n",
      "Match found: iOS 10\n"
     ]
    }
   ],
   "source": [
    "# 写一个模板，只匹配到所有提及完整iOS版本的部分： “iOS 7”，“iOS 11”和”iOS 10”。\n",
    "import spacy\n",
    "\n",
    "from spacy.matcher import Matcher\n",
    "nlp = spacy.load(\"zh_core_web_sm\")\n",
    "\n",
    "matcher = Matcher(nlp.vocab)\n",
    "\n",
    "doc = nlp(\n",
    "    \"升级iOS之后，我们并没有发现系统设计有很大的不同，远没有当年iOS 7发布时带来的\"\n",
    "    \"焕然一新的感觉。大部分iOS 11的设计与iOS 10保持一致。但我们仔细试用后也发现了一些\"\n",
    "    \"小的改进。\"\n",
    ")\n",
    "\n",
    "# 写一个模板来匹配完整的iOS版本 (\"iOS 7\", \"iOS 11\", \"iOS 10\")\n",
    "pattern = [{\"TEXT\":\"iOS\"}, {\"IS_DIGIT\": True}]\n",
    "\n",
    "matcher.add(\"IOS_VERSION_PATTERN\", [pattern])\n",
    "matches = matcher(doc)\n",
    "print(\"Total matches found:\", len(matches))\n",
    "\n",
    "# 遍历所有的匹配，然后打印span的文本\n",
    "for match_id, start, end in matches:\n",
    "    print(\"Match found:\", doc[start:end].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5d09e13f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total matches found: 2\n",
      "Match found: 下载Dota\n",
      "Match found: 下载Minecraft\n"
     ]
    }
   ],
   "source": [
    "# 写一个模板，只匹配到不同格式的”download”词（词符的原词是”download”）\n",
    "# 后面跟着一个词性是\"PROPN\"（专有名词）的词符。\n",
    "\n",
    "import spacy\n",
    "from spacy.matcher import Matcher\n",
    "\n",
    "nlp = spacy.load(\"zh_core_web_sm\")\n",
    "matcher = Matcher(nlp.vocab)\n",
    "\n",
    "doc = nlp(\n",
    "    \"我之前有去下载Dota到电脑上面，但是根本打不开游戏，怎么办？\"\n",
    "    \"我下载Minecraft，是Windows的版本，下载后是一个'.zip'的文件夹，然后我用了默认软件做了\"\n",
    "    \"解压...我是不是还需要去下载Winzip？\"\n",
    ")\n",
    "\n",
    "# 写一个模板来匹配\"下载\"加一个代词\n",
    "pattern = [{\"TEXT\": \"下载\"}, {\"POS\": \"PROPN\"}]\n",
    "\n",
    "# 把模板加入到matcher中，然后把matcher应用到doc上面\n",
    "matcher.add(\"DOWNLOAD_THINGS_PATTERN\", [pattern])\n",
    "matches = matcher(doc)\n",
    "print(\"Total matches found:\", len(matches))\n",
    "\n",
    "# 遍历所有的匹配，打印span的文本\n",
    "for match_id, start, end in matches:\n",
    "    print(\"Match found:\", doc[start:end].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d1749f4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total matches found: 4\n",
      "Match found: 优雅设计\n",
      "Match found: 快捷搜索\n",
      "Match found: 自动标签\n",
      "Match found: 可选声音\n"
     ]
    }
   ],
   "source": [
    "# 写一个模板，匹配到形容词（\"ADJ\"） \n",
    "# 后面跟着一两个名词\"NOUN\"（一个名词和另一个可能有的名词）。\n",
    "\n",
    "import spacy\n",
    "from spacy.matcher import Matcher\n",
    "\n",
    "nlp = spacy.load(\"zh_core_web_sm\")\n",
    "matcher = Matcher(nlp.vocab)\n",
    "\n",
    "doc = nlp(\n",
    "    \"这个app的特性包括了优雅设计、快捷搜索、自动标签以及可选声音。\"\n",
    ")\n",
    "\n",
    "pattern = [{\"POS\": \"ADJ\"}, {\"POS\": \"NOUN\"}, {\"POS\": \"NOUN\", \"OP\": \"?\"}]\n",
    "\n",
    "matcher.add(\"ADJ_NOUN_PATTERN\", [pattern])\n",
    "matches = matcher(doc)\n",
    "print(\"Total matches found:\", len(matches))\n",
    "\n",
    "# 遍历所有的匹配，打印span的文本\n",
    "for match_id, start, end in matches:\n",
    "    print(\"Match found:\", doc[start:end].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7296295",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
